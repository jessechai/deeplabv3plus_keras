{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3+ keras analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "KeyboardInterrupt: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6a3b176f9638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimsave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\skimage\\io\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_image_stack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanage_plugins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrgba2rgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexposure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_low_contrast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\skimage\\color\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from .colorconv import (convert_colorspace,\n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[0mguess_spatial_dimensions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0mrgba2rgb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mrgb2hsv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mhsv2rgb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\skimage\\color\\colorconv.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_limits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# This makes \"from scipy import fft\" return scipy.fft, not np.fft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\scipy\\fft\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m     hfft, ihfft, hfft2, ihfft2, hfftn, ihfftn)\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_realtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdctn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midctn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdstn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midstn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_helper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnext_fast_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m from ._backend import (set_backend, skip_backend, set_global_backend,\n\u001b[0;32m     81\u001b[0m                        register_backend)\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\scipy\\fft\\_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlru_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_pocketfft\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\scipy\\fft\\_pocketfft\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" FFT backend using pypocketfft \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrealtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\gutom\\anaconda3\\envs\\tf23_p38\\lib\\site-packages\\scipy\\fft\\_pocketfft\\basic.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpypocketfft\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m from .helper import (_asfarray, _init_nd_shape_and_axes, _datacopied,\n\u001b[0;32m      8\u001b[0m                      \u001b[0m_fix_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fix_shape_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_normalization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import platform\n",
    "import json\n",
    "import warnings\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage.io import imread, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import (Concatenate\n",
    "    , Lambda\n",
    "    , Activation\n",
    "    , AveragePooling2D\n",
    "    , SeparableConv2D)\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.utils import Sequence, GeneratorEnqueuer, OrderedEnqueuer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import math_ops, array_ops, confusion_matrix\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import iter_sequence_infinite\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "# Constants.\n",
    "DEBUG = True\n",
    "\n",
    "MODE_TRAIN = 0\n",
    "MODE_VAL = 1\n",
    "MODE_TEST = 2\n",
    "\n",
    "BASE_MODEL_MOBILENETV2 = 0\n",
    "BASE_MODEL_XCEPTION = 1\n",
    "\n",
    "RESOURCE_TYPE_PASCAL_VOC_2012 = 'pascal_voc_2012'\n",
    "RESOURCE_TYPE_PASCAL_VOC_2012_EXT = 'pascal_voc_2012_ext'\n",
    "RESOURCE_TYPE_GOOGLE_OPEN_IMAGES_V5 = 'google_open_images_v5'\n",
    "\n",
    "GOIV5_SPECIFIC_SET = set(['Person', 'Cat', 'Dog', 'Car', 'Bus', 'Motorcycle', 'Bicyle'])\n",
    "\n",
    "\n",
    "class MeanIoUExt(MeanIoU):\n",
    "    \"\"\"Calculate the mean IoU for one hot truth and prediction vectors.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, accum_enable=True, name=None, dtype=None):\n",
    "        super(MeanIoUExt, self).__init__(num_classes, name=name, dtype=dtype)\n",
    "        self.accum_enable = accum_enable\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Accumulated the confusion matrix statistics with one hot truth and prediction data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: Tensor or numpy array.\n",
    "            One hot ground truth vectors.\n",
    "        y_pred: Tensor or numpy array.\n",
    "            One hot predicted vectors.\n",
    "        sample_weight: Tensor.\n",
    "            Optional weighting of each example. Defaults to 1. Can be a\n",
    "            `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n",
    "            be broadcastable to `y_true`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Update operator.\n",
    "            Operator\n",
    "        \"\"\"\n",
    "        # Convert one hot vectors and labels.\n",
    "        y_pred = K.argmax(y_pred)\n",
    "\n",
    "        y_true = math_ops.cast(y_true, self._dtype)\n",
    "        y_pred = math_ops.cast(y_pred, self._dtype)\n",
    "\n",
    "        # Flatten the input if its rank > 1.\n",
    "        if y_pred.shape.ndims > 1:\n",
    "            y_pred = array_ops.reshape(y_pred, [-1])\n",
    "\n",
    "        if y_true.shape.ndims > 1:\n",
    "            y_true = array_ops.reshape(y_true, [-1])\n",
    "\n",
    "        if sample_weight is not None and sample_weight.shape.ndims > 1:\n",
    "            sample_weight = array_ops.reshape(sample_weight, [-1])\n",
    "\n",
    "        # Accumulate the prediction to current confusion matrix.\n",
    "        current_cm = confusion_matrix.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            self.num_classes,\n",
    "            weights=sample_weight,\n",
    "            dtype=dtypes.float64)\n",
    "        return self.total_cm.assign_add(current_cm) if self.accum_enable \\\n",
    "            else self.total_cm.assign(current_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(label, num_classes):\n",
    "    \"\"\"Get one hot tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label: Numpy array.\n",
    "        label.\n",
    "    num_classes: Integer\n",
    "        Number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    One hot.\n",
    "        Numpy array.\n",
    "    \"\"\"\n",
    "    indexes = label.ravel()\n",
    "    shape = tuple(list(label.shape) + [num_classes])\n",
    "    onehot = np.zeros(shape=shape)\n",
    "    onehot = onehot.ravel()\n",
    "\n",
    "    for i in range(label.size):\n",
    "        onehot[i * num_classes + indexes[i]] = 1\n",
    "\n",
    "    onehot = onehot.reshape(shape)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random generators.\n",
    "seed = int(time.time())\n",
    "seed = 1024\n",
    "print(f'Seed:{seed}')\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile semantic_segmentation_deeplabv3plus_conf.json\n",
    "{\n",
    "\t\"mode\" : \"train\",\n",
    "\t\"resource_type\": \"pascal_voc_2012_ext\",\n",
    "\t\"resource_path\" : \"Z:\\\\maum\\\\workspace_resource\\\\deeplabv3plus_keras\\\\resource\",\n",
    "\t\"model_loading\" : false,\n",
    "\t\"multi_gpu\" : false,\n",
    "\t\"num_gpus\" : 4,\n",
    "\t\"eval_data_mode\": 1,\n",
    "\t\"eval_result_saving\": false,\n",
    "\t\"base_model\": 0,\n",
    "\t\"hps\" : {\n",
    "\t\t\"val_ratio\": 0.1,\n",
    "\t\t\"lr\" : 0.0001,\n",
    "\t\t\"beta_1\" : 0.5,\n",
    "\t\t\"beta_2\" : 0.99,\n",
    "\t\t\"decay\" : 0.0,\n",
    "\t\t\"epochs\" : 2,\n",
    "\t\t\"batch_size\" : 1,\n",
    "\t\t\"weight_decay\": 0.00004,\n",
    "\t\t\"bn_momentum\": 0.9,\n",
    "\t\t\"bn_scale\": true,\n",
    "\t\t\"reduce_lr_factor\": 0.99\n",
    "\t},\n",
    "\t\"nn_arch\" : {\n",
    "\t\t\"boundary_refinement\": true,\n",
    "\t\t\"output_stride\": 16,\n",
    "\t\t\"image_size\": 512,\n",
    "\t\t\"num_classes\": 21,\n",
    "\t\t\"mv2_depth_multiplier\": 1,\n",
    "\t\t\"depth_multiplier\": 1,\n",
    "\t\t\"conv_rate_multiplier\" : 1,\n",
    "\t\t\"reduction_size\": 256,\n",
    "\t\t\"dropout_rate\": 0.5,\n",
    "\t\t\"concat_channels\": 256,\n",
    "\t\t\"encoder_middle_conf\": [\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": -1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [18, 15], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 3], \"op\": \"conv\", \"input\": 1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 21], \"op\": \"conv\", \"input\": 0}\n",
    "\t\t],\n",
    "\t\t\"encoder_middle_conf_xception\": [\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": -1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 6], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [12, 12], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [18, 18], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 1, \"rate\": [1, 1], \"op\": \"pyramid_pooling\", \"input\": 0, \"target_size_factor\": [1, 1]}\n",
    "\t\t]\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"semantic_segmentation_deeplabv3plus_conf.json\", 'r') as f:\n",
    "    conf = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ss_class_imbalance_weights(resource_path, size=21):\n",
    "    with open(os.path.join(resource_path\n",
    "                           , 'VOCdevkit'\n",
    "                           , 'VOC2012'\n",
    "                           , 'ImageSets'\n",
    "                           , 'Segmentation'\n",
    "                           , 'train_aug_val.txt')) as f:\n",
    "        file_names = f.readlines() #?\n",
    "    \n",
    "    # Remove \\n.\n",
    "    for i in range(len(file_names)):\n",
    "        file_names[i] = file_names[i][:-1]\n",
    "        \n",
    "    label_dir_path = os.path.join(resource_path\n",
    "                           , 'VOCdevkit'\n",
    "                           , 'VOC2012'\n",
    "                           , 'SegmentationClassAug')\n",
    "\n",
    "    pf = np.zeros(size)\n",
    "    total_num = 0.0\n",
    "\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        file_name = file_names[i]\n",
    "        \n",
    "        # Load label.\n",
    "        label_path = os.path.join(label_dir_path, file_name + '.png') #?\n",
    "        label = imread(label_path)\n",
    "        \n",
    "        label[label > (size - 1)] = 0        \n",
    "        label_oh = get_one_hot(label, size)\n",
    "        label2 = label_oh.reshape(np.prod(label.shape), size)\n",
    "        label_pf = label2.sum(axis=0)\n",
    "        pf = pf + label_pf\n",
    "        total_num += np.prod(label.shape)\n",
    "        \n",
    "        if label_pf.sum() != np.prod(label.shape):\n",
    "            print(f'{label_pf.sum()}, {np.prod(label.shape)}')\n",
    "\n",
    "    pf = pf / total_num\n",
    "    nf = 1.0 - pf\n",
    "    pw = nf\n",
    "    nw = pf\n",
    "\n",
    "    print(f'pw: {pw}, nw: {nw}')\n",
    "    return pw, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.runcall(cal_ss_class_imbalance_weights, conf['resource_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw, nw = cal_ss_class_imbalance_weights(conf['resource_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function resize:\n",
      "\n",
      "resize(...)\n",
      "    resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
      "    .   @brief Resizes an image.\n",
      "    .   \n",
      "    .   The function resize resizes the image src down to or up to the specified size. Note that the\n",
      "    .   initial dst type or size are not taken into account. Instead, the size and type are derived from\n",
      "    .   the `src`,`dsize`,`fx`, and `fy`. If you want to resize src so that it fits the pre-created dst,\n",
      "    .   you may call the function as follows:\n",
      "    .   @code\n",
      "    .       // explicitly specify dsize=dst.size(); fx and fy will be computed from that.\n",
      "    .       resize(src, dst, dst.size(), 0, 0, interpolation);\n",
      "    .   @endcode\n",
      "    .   If you want to decimate the image by factor of 2 in each direction, you can call the function this\n",
      "    .   way:\n",
      "    .   @code\n",
      "    .       // specify fx and fy and let the function compute the destination image size.\n",
      "    .       resize(src, dst, Size(), 0.5, 0.5, interpolation);\n",
      "    .   @endcode\n",
      "    .   To shrink an image, it will generally look best with #INTER_AREA interpolation, whereas to\n",
      "    .   enlarge an image, it will generally look best with c#INTER_CUBIC (slow) or #INTER_LINEAR\n",
      "    .   (faster but still looks OK).\n",
      "    .   \n",
      "    .   @param src input image.\n",
      "    .   @param dst output image; it has the size dsize (when it is non-zero) or the size computed from\n",
      "    .   src.size(), fx, and fy; the type of dst is the same as of src.\n",
      "    .   @param dsize output image size; if it equals zero, it is computed as:\n",
      "    .    \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "    .    Either dsize or both fx and fy must be non-zero.\n",
      "    .   @param fx scale factor along the horizontal axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "    .   @param fy scale factor along the vertical axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "    .   @param interpolation interpolation method, see #InterpolationFlags\n",
      "    .   \n",
      "    .   @sa  warpAffine, warpPerspective, remap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
