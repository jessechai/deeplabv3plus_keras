{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3+ keras analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import platform\n",
    "import json\n",
    "import warnings\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage.io import imread, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import (Concatenate\n",
    "    , Lambda\n",
    "    , Activation\n",
    "    , AveragePooling2D\n",
    "    , SeparableConv2D)\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.utils import Sequence, GeneratorEnqueuer, OrderedEnqueuer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import math_ops, array_ops, confusion_matrix\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import iter_sequence_infinite\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "# Constants.\n",
    "DEBUG = True\n",
    "\n",
    "MODE_TRAIN = 0\n",
    "MODE_VAL = 1\n",
    "MODE_TEST = 2\n",
    "\n",
    "BASE_MODEL_MOBILENETV2 = 0\n",
    "BASE_MODEL_XCEPTION = 1\n",
    "\n",
    "RESOURCE_TYPE_PASCAL_VOC_2012 = 'pascal_voc_2012'\n",
    "RESOURCE_TYPE_PASCAL_VOC_2012_EXT = 'pascal_voc_2012_ext'\n",
    "RESOURCE_TYPE_GOOGLE_OPEN_IMAGES_V5 = 'google_open_images_v5'\n",
    "\n",
    "GOIV5_SPECIFIC_SET = set(['Person', 'Cat', 'Dog', 'Car', 'Bus', 'Motorcycle', 'Bicyle'])\n",
    "\n",
    "\n",
    "class MeanIoUExt(MeanIoU):\n",
    "    \"\"\"Calculate the mean IoU for one hot truth and prediction vectors.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, accum_enable=True, name=None, dtype=None):\n",
    "        super(MeanIoUExt, self).__init__(num_classes, name=name, dtype=dtype)\n",
    "        self.accum_enable = accum_enable\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Accumulated the confusion matrix statistics with one hot truth and prediction data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: Tensor or numpy array.\n",
    "            One hot ground truth vectors.\n",
    "        y_pred: Tensor or numpy array.\n",
    "            One hot predicted vectors.\n",
    "        sample_weight: Tensor.\n",
    "            Optional weighting of each example. Defaults to 1. Can be a\n",
    "            `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n",
    "            be broadcastable to `y_true`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Update operator.\n",
    "            Operator\n",
    "        \"\"\"\n",
    "        # Convert one hot vectors and labels.\n",
    "        y_pred = K.argmax(y_pred)\n",
    "\n",
    "        y_true = math_ops.cast(y_true, self._dtype)\n",
    "        y_pred = math_ops.cast(y_pred, self._dtype)\n",
    "\n",
    "        # Flatten the input if its rank > 1.\n",
    "        if y_pred.shape.ndims > 1:\n",
    "            y_pred = array_ops.reshape(y_pred, [-1])\n",
    "\n",
    "        if y_true.shape.ndims > 1:\n",
    "            y_true = array_ops.reshape(y_true, [-1])\n",
    "\n",
    "        if sample_weight is not None and sample_weight.shape.ndims > 1:\n",
    "            sample_weight = array_ops.reshape(sample_weight, [-1])\n",
    "\n",
    "        # Accumulate the prediction to current confusion matrix.\n",
    "        current_cm = confusion_matrix.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            self.num_classes,\n",
    "            weights=sample_weight,\n",
    "            dtype=dtypes.float64)\n",
    "        return self.total_cm.assign_add(current_cm) if self.accum_enable \\\n",
    "            else self.total_cm.assign(current_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(label, num_classes):\n",
    "    \"\"\"Get one hot tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label: Numpy array.\n",
    "        label.\n",
    "    num_classes: Integer\n",
    "        Number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    One hot.\n",
    "        Numpy array.\n",
    "    \"\"\"\n",
    "    indexes = label.ravel()\n",
    "    shape = tuple(list(label.shape) + [num_classes])\n",
    "    onehot = np.zeros(shape=shape)\n",
    "    onehot = onehot.ravel()\n",
    "\n",
    "    for i in range(label.size):\n",
    "        onehot[i * num_classes + indexes[i]] = 1\n",
    "\n",
    "    onehot = onehot.reshape(shape)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:1024\n"
     ]
    }
   ],
   "source": [
    "# Initialize random generators.\n",
    "seed = int(time.time())\n",
    "seed = 1024\n",
    "print(f'Seed:{seed}')\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting semantic_segmentation_deeplabv3plus_conf.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile semantic_segmentation_deeplabv3plus_conf.json\n",
    "{\n",
    "\t\"mode\" : \"train\",\n",
    "\t\"resource_type\": \"pascal_voc_2012_ext\",\n",
    "\t\"resource_path\" : \"Z:\\\\maum\\\\workspace_resource\\\\deeplabv3plus_keras\\\\resource\",\n",
    "\t\"model_loading\" : false,\n",
    "\t\"multi_gpu\" : false,\n",
    "\t\"num_gpus\" : 4,\n",
    "\t\"eval_data_mode\": 1,\n",
    "\t\"eval_result_saving\": false,\n",
    "\t\"base_model\": 0,\n",
    "\t\"hps\" : {\n",
    "\t\t\"val_ratio\": 0.1,\n",
    "\t\t\"lr\" : 0.0001,\n",
    "\t\t\"beta_1\" : 0.5,\n",
    "\t\t\"beta_2\" : 0.99,\n",
    "\t\t\"decay\" : 0.0,\n",
    "\t\t\"epochs\" : 2,\n",
    "\t\t\"batch_size\" : 1,\n",
    "\t\t\"weight_decay\": 0.00004,\n",
    "\t\t\"bn_momentum\": 0.9,\n",
    "\t\t\"bn_scale\": true,\n",
    "\t\t\"reduce_lr_factor\": 0.99\n",
    "\t},\n",
    "\t\"nn_arch\" : {\n",
    "\t\t\"boundary_refinement\": true,\n",
    "\t\t\"output_stride\": 16,\n",
    "\t\t\"image_size\": 512,\n",
    "\t\t\"num_classes\": 21,\n",
    "\t\t\"mv2_depth_multiplier\": 1,\n",
    "\t\t\"depth_multiplier\": 1,\n",
    "\t\t\"conv_rate_multiplier\" : 1,\n",
    "\t\t\"reduction_size\": 256,\n",
    "\t\t\"dropout_rate\": 0.5,\n",
    "\t\t\"concat_channels\": 256,\n",
    "\t\t\"encoder_middle_conf\": [\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": -1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [18, 15], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 3], \"op\": \"conv\", \"input\": 1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 21], \"op\": \"conv\", \"input\": 0}\n",
    "\t\t],\n",
    "\t\t\"encoder_middle_conf_xception\": [\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [1, 1], \"op\": \"conv\", \"input\": -1},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [6, 6], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [12, 12], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 3, \"rate\": [18, 18], \"op\": \"conv\", \"input\": 0},\n",
    "\t\t\t{\"kernel\": 1, \"rate\": [1, 1], \"op\": \"pyramid_pooling\", \"input\": 0, \"target_size_factor\": [1, 1]}\n",
    "\t\t]\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"semantic_segmentation_deeplabv3plus_conf.json\", 'r') as f:\n",
    "    conf = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ss_class_imbalance_weights(resource_path, size=21):\n",
    "    with open(os.path.join(resource_path\n",
    "                           , 'VOCdevkit'\n",
    "                           , 'VOC2012'\n",
    "                           , 'ImageSets'\n",
    "                           , 'Segmentation'\n",
    "                           , 'train_aug_val.txt')) as f:\n",
    "        file_names = f.readlines() #?\n",
    "    \n",
    "    # Remove \\n.\n",
    "    for i in range(len(file_names)):\n",
    "        file_names[i] = file_names[i][:-1]\n",
    "        \n",
    "    label_dir_path = os.path.join(resource_path\n",
    "                           , 'VOCdevkit'\n",
    "                           , 'VOC2012'\n",
    "                           , 'SegmentationClassAug')\n",
    "\n",
    "    pf = np.zeros(size)\n",
    "    total_num = 0.0\n",
    "\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        file_name = file_names[i]\n",
    "        \n",
    "        # Load label.\n",
    "        label_path = os.path.join(label_dir_path, file_name + '.png') #?\n",
    "        label = imread(label_path)\n",
    "        \n",
    "        label[label > (size - 1)] = 0        \n",
    "        label_oh = get_one_hot(label, size)\n",
    "        label2 = label_oh.reshape(np.prod(label.shape), size)\n",
    "        label_pf = label2.sum(axis=0)\n",
    "        pf = pf + label_pf\n",
    "        total_num += np.prod(label.shape)\n",
    "        \n",
    "        if label_pf.sum() != np.prod(label.shape):\n",
    "            print(f'{label_pf.sum()}, {np.prod(label.shape)}')\n",
    "\n",
    "    pf = pf / total_num\n",
    "    nf = 1.0 - pf\n",
    "    pw = nf\n",
    "    nw = pf\n",
    "\n",
    "    print(f'pw: {pw}, nw: {nw}')\n",
    "    return pw, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-26-9cb1f0cb93b8>\u001b[0m(2)\u001b[0;36mcal_ss_class_imbalance_weights\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;32mdef\u001b[0m \u001b[0mcal_ss_class_imbalance_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m    with open(os.path.join(resource_path\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m                           \u001b[1;33m,\u001b[0m \u001b[1;34m'VOCdevkit'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m                           \u001b[1;33m,\u001b[0m \u001b[1;34m'VOC2012'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m                           \u001b[1;33m,\u001b[0m \u001b[1;34m'ImageSets'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> tbreak 40\n",
      "Breakpoint 8 at <ipython-input-26-9cb1f0cb93b8>:40\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████▊| 11987/12031 [2:23:40<00:30,  1.45it/s]<ipython-input-26-9cb1f0cb93b8>:34: RuntimeWarning: overflow encountered in long_scalars\n",
      "  total_num += np.prod(label.shape)\n",
      "100%|█████████████████████████████████████████████████████| 12031/12031 [2:24:09<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted breakpoint 8 at <ipython-input-26-9cb1f0cb93b8>:40\n",
      "> \u001b[1;32m<ipython-input-26-9cb1f0cb93b8>\u001b[0m(40)\u001b[0;36mcal_ss_class_imbalance_weights\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     38 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     39 \u001b[1;33m    \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpf\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 40 \u001b[1;33m    \u001b[0mnf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     41 \u001b[1;33m    \u001b[0mpw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     42 \u001b[1;33m    \u001b[0mnw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> pf\n",
      "array([-0.70755247, -0.00899598, -0.00769173, -0.00883414, -0.00654323,\n",
      "       -0.00548468, -0.01280812, -0.01923425, -0.03139148, -0.01255932,\n",
      "       -0.00628141, -0.01065069, -0.02797298, -0.00926101, -0.01163078,\n",
      "       -0.07447052, -0.00611032, -0.00630222, -0.01226675, -0.0135008 ,\n",
      "       -0.00772092])\n",
      "ipdb> total_num\n",
      "-2139712417\n",
      "ipdb> pf = pf * total_num\n",
      "ipdb> of\n",
      "*** NameError: name 'of' is not defined\n",
      "ipdb> pf\n",
      "array([1.51395881e+09, 1.92488160e+07, 1.64580820e+07, 1.89025120e+07,\n",
      "       1.40006320e+07, 1.17356420e+07, 2.74056960e+07, 4.11557630e+07,\n",
      "       6.71687460e+07, 2.68733240e+07, 1.34404170e+07, 2.27894140e+07,\n",
      "       5.98541240e+07, 1.98158910e+07, 2.48865300e+07, 1.59345498e+08,\n",
      "       1.30743380e+07, 1.34849450e+07, 2.62473170e+07, 2.88878260e+07,\n",
      "       1.65205550e+07])\n",
      "ipdb> pf.sum()\n",
      "2155254879.0\n",
      "ipdb> pf = pf / total_num\n",
      "ipdb> pf\n",
      "array([-0.70755247, -0.00899598, -0.00769173, -0.00883414, -0.00654323,\n",
      "       -0.00548468, -0.01280812, -0.01923425, -0.03139148, -0.01255932,\n",
      "       -0.00628141, -0.01065069, -0.02797298, -0.00926101, -0.01163078,\n",
      "       -0.07447052, -0.00611032, -0.00630222, -0.01226675, -0.0135008 ,\n",
      "       -0.00772092])\n",
      "ipdb> n\n",
      "> \u001b[1;32m<ipython-input-26-9cb1f0cb93b8>\u001b[0m(41)\u001b[0;36mcal_ss_class_imbalance_weights\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     39 \u001b[1;33m    \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpf\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     40 \u001b[1;33m    \u001b[0mnf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 41 \u001b[1;33m    \u001b[0mpw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     42 \u001b[1;33m    \u001b[0mnw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     43 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> nf\n",
      "array([1.70755247, 1.00899598, 1.00769173, 1.00883414, 1.00654323,\n",
      "       1.00548468, 1.01280812, 1.01923425, 1.03139148, 1.01255932,\n",
      "       1.00628141, 1.01065069, 1.02797298, 1.00926101, 1.01163078,\n",
      "       1.07447052, 1.00611032, 1.00630222, 1.01226675, 1.0135008 ,\n",
      "       1.00772092])\n",
      "ipdb> type(total_num)\n",
      "<class 'numpy.int32'>\n",
      "ipdb> total_num\n",
      "-2139712417\n",
      "ipdb> pf.dtype\n",
      "dtype('float64')\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "pdb.runcall(cal_ss_class_imbalance_weights, conf['resource_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 12031/12031 [1:52:41<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pw: [0.29754999 0.99106889 0.99236374 0.99122957 0.99350396 0.99455487\n",
      " 0.98728424 0.98090446 0.96883489 0.98753125 0.99376389 0.98942612\n",
      " 0.97222875 0.99080578 0.98845309 0.92606652 0.99393374 0.99374322\n",
      " 0.98782171 0.98659656 0.99233476], nw: [0.70245001 0.00893111 0.00763626 0.00877043 0.00649604 0.00544513\n",
      " 0.01271576 0.01909554 0.03116511 0.01246875 0.00623611 0.01057388\n",
      " 0.02777125 0.00919422 0.01154691 0.07393348 0.00606626 0.00625678\n",
      " 0.01217829 0.01340344 0.00766524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pw, nw = cal_ss_class_imbalance_weights(conf['resource_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
